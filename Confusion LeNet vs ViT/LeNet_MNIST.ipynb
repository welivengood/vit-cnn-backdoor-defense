{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0ae270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 11:39:24.448434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-23 11:39:24.456366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750696764.464815   21895 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750696764.467548   21895 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750696764.475173   21895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750696764.475184   21895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750696764.475185   21895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750696764.475186   21895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-23 11:39:24.478227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702cd66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1307]), tensor([0.3081]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Calculate mean and std\n",
    "imgs = torch.stack([img for img, _ in train_val_dataset], dim=0)\n",
    "\n",
    "mean = imgs.view(1, -1).mean(dim=1)    # or imgs.mean()\n",
    "std = imgs.view(1, -1).std(dim=1)     # or imgs.std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a630a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mnist_dataset(image_size=28, batch_size=32):\n",
    "\n",
    "    # Redundant resizing since images are already 28x28\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "# Gets train and test samples from MNIST with batch size overridden to 256\n",
    "train_val_dataset, test_dataset = get_mnist_dataset(batch_size=256)\n",
    "\n",
    "train_size = int(0.9 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_val_dataset, lengths=[train_size, val_size])\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26258492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1688, 188, 313)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)  # SHUFFLE FALSE\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)    # SHUFFLE FALSE\n",
    "\n",
    "\n",
    "# Let's see no of batches that we have now with the current batch-size\n",
    "len(train_loader), len(val_loader), len(test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f943b030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "LeNet5V1 (LeNet5V1)                      [1, 1, 28, 28]       [1, 10]              --                   True\n",
       "├─Sequential (feature)                   [1, 1, 28, 28]       [1, 16, 5, 5]        --                   True\n",
       "│    └─Conv2d (0)                        [1, 1, 28, 28]       [1, 6, 28, 28]       156                  True\n",
       "│    └─Tanh (1)                          [1, 6, 28, 28]       [1, 6, 28, 28]       --                   --\n",
       "│    └─AvgPool2d (2)                     [1, 6, 28, 28]       [1, 6, 14, 14]       --                   --\n",
       "│    └─Conv2d (3)                        [1, 6, 14, 14]       [1, 16, 10, 10]      2,416                True\n",
       "│    └─Tanh (4)                          [1, 16, 10, 10]      [1, 16, 10, 10]      --                   --\n",
       "│    └─AvgPool2d (5)                     [1, 16, 10, 10]      [1, 16, 5, 5]        --                   --\n",
       "├─Sequential (classifier)                [1, 16, 5, 5]        [1, 10]              --                   True\n",
       "│    └─Flatten (0)                       [1, 16, 5, 5]        [1, 400]             --                   --\n",
       "│    └─Linear (1)                        [1, 400]             [1, 120]             48,120               True\n",
       "│    └─Tanh (2)                          [1, 120]             [1, 120]             --                   --\n",
       "│    └─Linear (3)                        [1, 120]             [1, 84]              10,164               True\n",
       "│    └─Tanh (4)                          [1, 84]              [1, 84]              --                   --\n",
       "│    └─Linear (5)                        [1, 84]              [1, 10]              850                  True\n",
       "========================================================================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.42\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.30\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet5V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
    "            \n",
    "            #2\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))\n",
    "    \n",
    "model_lenet5v1 = LeNet5V1()\n",
    "\n",
    "summary(model=model_lenet5v1, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0483729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_lenet5v1.parameters(), lr=0.001)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b428bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train loss:  0.24928| Train acc:  0.92493| Val loss:  0.11850| Val acc:  0.96443\n",
      "Epoch: 1| Train loss:  0.08765| Train acc:  0.97325| Val loss:  0.07284| Val acc:  0.97540\n",
      "Epoch: 2| Train loss:  0.06070| Train acc:  0.98115| Val loss:  0.06848| Val acc:  0.97955\n",
      "Epoch: 3| Train loss:  0.04816| Train acc:  0.98473| Val loss:  0.06473| Val acc:  0.98039\n",
      "Epoch: 4| Train loss:  0.03788| Train acc:  0.98747| Val loss:  0.06029| Val acc:  0.98188\n",
      "Epoch: 5| Train loss:  0.03174| Train acc:  0.99015| Val loss:  0.05347| Val acc:  0.98421\n",
      "Epoch: 6| Train loss:  0.02743| Train acc:  0.99106| Val loss:  0.05025| Val acc:  0.98654\n",
      "Epoch: 7| Train loss:  0.02325| Train acc:  0.99206| Val loss:  0.04689| Val acc:  0.98654\n",
      "Epoch: 8| Train loss:  0.02004| Train acc:  0.99378| Val loss:  0.04775| Val acc:  0.98604\n",
      "Epoch: 9| Train loss:  0.01797| Train acc:  0.99387| Val loss:  0.05797| Val acc:  0.98388\n",
      "Epoch: 10| Train loss:  0.01831| Train acc:  0.99389| Val loss:  0.04894| Val acc:  0.98753\n",
      "Epoch: 11| Train loss:  0.01213| Train acc:  0.99609| Val loss:  0.05867| Val acc:  0.98454\n"
     ]
    }
   ],
   "source": [
    "# Experiment tracking\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "experiment_name = \"MNIST\"\n",
    "model_name = \"LeNet5V1\"\n",
    "log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# device-agnostic setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "accuracy = accuracy.to(device)\n",
    "model_lenet5v1 = model_lenet5v1.to(device)\n",
    "\n",
    "EPOCHS = 12\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training loop\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        model_lenet5v1.train()\n",
    "        \n",
    "        y_pred = model_lenet5v1(X)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        acc = accuracy(y_pred, y)\n",
    "        train_acc += acc\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "        \n",
    "    # Validation loop\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    model_lenet5v1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model_lenet5v1(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            acc = accuracy(y_pred, y)\n",
    "            val_acc += acc\n",
    "            \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        \n",
    "    writer.add_scalars(main_tag=\"Loss\", tag_scalar_dict={\"train/loss\": train_loss, \"val/loss\": val_loss}, global_step=epoch)\n",
    "    writer.add_scalars(main_tag=\"Accuracy\", tag_scalar_dict={\"train/acc\": train_acc, \"val/acc\": val_acc}, global_step=epoch)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_acc: .5f}| Val loss: {val_loss: .5f}| Val acc: {val_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c82b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.05004| Test acc:  0.98672\n"
     ]
    }
   ],
   "source": [
    "# Use testing set for a final evaluation\n",
    "\n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "model_lenet5v1.to(device)\n",
    "\n",
    "model_lenet5v1.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model_lenet5v1(X)\n",
    "        \n",
    "        test_loss += loss_fn(y_pred, y)\n",
    "        test_acc += accuracy(y_pred, y)\n",
    "        \n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "\n",
    "print(f\"Test loss: {test_loss: .5f}| Test acc: {test_acc: .5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
